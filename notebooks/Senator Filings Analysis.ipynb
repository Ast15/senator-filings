{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senator Filings Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime as dt\n",
    "from functools import lru_cache\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we explore stock orders that were publicly filed by U.S. senators. The filings are scraped from https://efdsearch.senate.gov/search/. We calculate the returns of each senator by mimicking their buys and sells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The `senators.pickle` file is scraped using the script in the root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('senators.pickle', 'rb') as f:\n",
    "    senators_tx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we fill in as many of the missing ticker symbols as we can. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(asset_name):\n",
    "    \"\"\" Convert an asset name into useful tokens. \"\"\"\n",
    "    token_string = asset_name\\\n",
    "        .replace('(', '')\\\n",
    "        .replace(')', '')\\\n",
    "        .replace('-', ' ')\\\n",
    "        .replace('.', '')\n",
    "    return token_string.split(' ')\n",
    "\n",
    "def token_is_ticker(token, token_blacklist):\n",
    "    return len(token) <= 4 and token.upper() not in token_blacklist\n",
    "\n",
    "# These generic words do not help us determine the ticker\n",
    "blacklist = {\n",
    "    \"1\",\n",
    "    \"180\",\n",
    "    \"21ST\",\n",
    "    \"66\",\n",
    "    \"A\",\n",
    "    \"AB\",\n",
    "    \"ADR\",\n",
    "    \"ATK\",\n",
    "    \"B\",\n",
    "    \"BANK\",\n",
    "    \"C\",\n",
    "    \"CMN\",\n",
    "    \"CO\",\n",
    "    \"COM\",\n",
    "    \"CORP\",\n",
    "    \"DEL\",\n",
    "    \"E\",\n",
    "    \"ETF\",\n",
    "    \"FD\",\n",
    "    \"FUND\",\n",
    "    \"GROW\",\n",
    "    \"GRP\",\n",
    "    \"HACK\",\n",
    "    \"HLDG\",\n",
    "    \"HOME\",\n",
    "    \"INC\",\n",
    "    \"INTL\",\n",
    "    \"INV\",\n",
    "    \"IRON\",\n",
    "    \"LABS\",\n",
    "    \"LP\",\n",
    "    \"LTD\",\n",
    "    \"MDA\",\n",
    "    \"N/L\",\n",
    "    \"NEW\",\n",
    "    \"PFD\",\n",
    "    \"PLC\",\n",
    "    \"PUT\",\n",
    "    \"SA\",\n",
    "    \"SD\",\n",
    "    \"SE\",\n",
    "    \"SHRS\",\n",
    "    \"SHS\",\n",
    "    \"SPDR\",\n",
    "    \"TD\",\n",
    "    \"TF\",\n",
    "    \"THE\",\n",
    "    \"TR\",\n",
    "    \"UNIT\",\n",
    "    \"US\",\n",
    "    \"VCA\",\n",
    "    \"WALT\"\n",
    "}\n",
    "\n",
    "missing_tickers = set(senators_tx[\n",
    "    (senators_tx['ticker'] == '--')\n",
    "    | (senators_tx['ticker'] == '')\n",
    "]['asset_name'])\n",
    "\n",
    "ticker_map = {}\n",
    "unmapped_tickers = set()\n",
    "for m in missing_tickers:\n",
    "    tokens = tokenize(m)\n",
    "    if token_is_ticker(tokens[0], blacklist):\n",
    "        ticker_map[m] = tokens[0].upper()\n",
    "        continue\n",
    "    elif token_is_ticker(tokens[-1], blacklist):\n",
    "        ticker_map[m] = tokens[-1].upper()\n",
    "        continue\n",
    "    unmapped_tickers.add(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a second pass, we assign tickers to asset names that have any of the specified keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_to_ticker = {\n",
    "    'FOX': 'FOX',\n",
    "    'AMAZON': 'AMZN',\n",
    "    'AARON': 'AAN',\n",
    "    'ALTRIA': 'MO',\n",
    "    'APPLE': 'AAPL',\n",
    "    'CHEVRON': 'CVX',\n",
    "    'DUPONT': 'DD',\n",
    "    'ALPHABET': 'GOOGL',\n",
    "    'GOOG': 'GOOGL',\n",
    "    'GENERAL ELECTRIC': 'GE',\n",
    "    'JOHNSON': 'JNJ',\n",
    "    'NEWELL': 'NWL',\n",
    "    'OWENS': 'OMI',\n",
    "    'PFIZER': 'PFE',\n",
    "    'TYSON': 'TSN',\n",
    "    'UNDER ARMOUR': 'UAA',\n",
    "    'VERIZON': 'VZ',\n",
    "    'WALT': 'DIS'\n",
    "}\n",
    "\n",
    "for m in unmapped_tickers:\n",
    "    for t in phrase_to_ticker:\n",
    "        if t in m.upper():\n",
    "            ticker_map[m] = phrase_to_ticker[t]\n",
    "\n",
    "clean_senators = senators_tx.copy()\n",
    "for a, t in ticker_map.items():\n",
    "    clean_senators.loc[clean_senators['asset_name'] == a, 'ticker'] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out useless rows and missing symbols, and then add some useful columns for the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_senators = clean_senators[clean_senators['ticker'] != '--']\n",
    "clean_senators = clean_senators.assign(\n",
    "    ticker=clean_senators['ticker'].map(\n",
    "        lambda s: s.replace('--', '').replace('\\n', '')))\n",
    "\n",
    "clean_senators = clean_senators[clean_senators['order_type'] != 'Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_tx_amount(amt):\n",
    "    \"\"\" Get the lower bound for the transaction amount. \"\"\"\n",
    "    try:\n",
    "        return int(amt.replace('Over $50,000,000', '50000000')\n",
    "                   .split(' - ')[0]\n",
    "                   .replace(',' ,'')\n",
    "                   .replace('$' ,''))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "clean_senators = clean_senators.assign(\n",
    "    tx_estimate=clean_senators['tx_amount'].map(parse_tx_amount))\n",
    "full_name =\\\n",
    "    clean_senators['first_name'] + ' ' + clean_senators['last_name']\n",
    "clean_senators = clean_senators.assign(full_name=full_name)\n",
    "useful_cols = [\n",
    "    'file_date',\n",
    "    'tx_date',\n",
    "    'full_name',\n",
    "    'order_type',\n",
    "    'ticker',\n",
    "    'tx_estimate'\n",
    "]\n",
    "clean_senators = clean_senators[useful_cols]\n",
    "clean_senators = clean_senators.assign(\n",
    "    tx_date=clean_senators['tx_date'].map(\n",
    "        lambda v: dt.datetime.strptime(v, '%m/%d/%Y')))\n",
    "clean_senators = clean_senators.assign(\n",
    "    file_date=clean_senators['file_date'].map(\n",
    "        lambda v: dt.datetime.strptime(v, '%m/%d/%Y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells help us download the market data for the specified tickers. We store the market data in files so we don't need to repeatedly download the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_for_ticker(ticker, cache_check=True):\n",
    "    if cache_check and path.exists('stocks/{0}.pickle'.format(ticker)):\n",
    "        return\n",
    "    d = yf.Ticker(ticker)\n",
    "    with open('stocks/{0}.pickle'.format(ticker), 'wb') as f:\n",
    "        shares = 1\n",
    "        try:\n",
    "            shares = d.info['sharesOutstanding']\n",
    "        except:\n",
    "            # Swallow missing shares outstanding\n",
    "            pass\n",
    "        pickle.dump({\n",
    "            'price': d.history(period=\"max\").reset_index(),\n",
    "            'shares': shares\n",
    "        }, f)\n",
    "\n",
    "def load_for_ticker(ticker):\n",
    "    with open('stocks/{0}.pickle'.format(ticker), 'rb') as f:\n",
    "        dump = pickle.load(f)\n",
    "    raw = dump['price']\n",
    "    raw = raw.assign(market_cap=raw['Close'] * dump['shares'])\n",
    "    return raw[['Date', 'Close', 'market_cap']]\\\n",
    "        .rename(columns={'Date': 'date', 'Close': 'price'})\n",
    "\n",
    "def download_spy() -> None:\n",
    "    download_for_ticker('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tickers = set(clean_senators['ticker'])\n",
    "for i, t in enumerate(all_tickers):\n",
    "    if i % 100 == 0:\n",
    "        print('Working on ticker {0}'.format(i))\n",
    "    try:\n",
    "        download_for_ticker(t)\n",
    "    except Exception as e:\n",
    "        print('Ticker {0} failed with exception: {1}'.format(t, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimicking buy + sell orders\n",
    "\n",
    "We calculate a given senator's return by calculating the return between each buy or sell order, and then solving for the cumulative return. We convert that to a CAGR given the time period the senator was investing.\n",
    "\n",
    "We keep track of how many units of each stock a senator is holding. If we ever see a filing that indicates the senator sold more than we estimated they are holding, we just sell all of the units we have on record. (We do not allow the senator to go short.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buckets = [\n",
    "    (1000, 15000),\n",
    "    (15000, 50000),\n",
    "    (50000, 100000),\n",
    "    (100000, 250000),\n",
    "    (250000, 500000),\n",
    "    (500000, 1000000),\n",
    "    (1000000, 5000000),\n",
    "    (5000000, 25000000),\n",
    "    (25000000, 50000000),\n",
    "    (50000000, float('inf'))\n",
    "]\n",
    "\n",
    "def same_bucket(a, b):\n",
    "    \"\"\"\n",
    "    If the value of the stock units is roughly the same, sell all units\n",
    "    \"\"\"\n",
    "    for idx1, (v1, v2) in enumerate(buckets):\n",
    "        if a >= v1 and a < v2:\n",
    "            break\n",
    "    for idx2, (v1, v2) in enumerate(buckets):\n",
    "        if b >= v1 and b < v2:\n",
    "            break\n",
    "    return idx1 == idx2\n",
    "\n",
    "def _price_for_date(df, date):\n",
    "    df = df[df['date'] >= date].sort_values(by='date')\n",
    "    return df['price'].iloc[0]\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def ticker_at_date(ticker, date):\n",
    "    \"\"\" Price of a ticker at a given date. \"\"\"\n",
    "    try:\n",
    "        data = load_for_ticker(ticker)\n",
    "        # Sell at the next opportunity possible\n",
    "        return _price_for_date(data, date)\n",
    "    except:\n",
    "        download_for_ticker(ticker, cache_check=False)\n",
    "        data = load_for_ticker(ticker)\n",
    "        return _price_for_date(data, date)\n",
    "\n",
    "def portfolio_value(stocks, date):\n",
    "    \"\"\" Value of a portfolio assuming each ticker has the specified\n",
    "    number of units. \"\"\"\n",
    "    v = 0\n",
    "    for s, units in stocks.items():\n",
    "        if units == 0:\n",
    "            continue\n",
    "        try:\n",
    "            v += ticker_at_date(s, date) * units\n",
    "        except Exception as e:\n",
    "            print('Error calculating portfolio value: {}'.format(e))\n",
    "    return v\n",
    "\n",
    "def calculate_return(before_values,\n",
    "                     after_values,\n",
    "                     begin_date,\n",
    "                     end_date,\n",
    "                     tx_dates):\n",
    "    \"\"\" Calculate useful metrics given the senators portfolio value\n",
    "    over time. \"\"\"\n",
    "    before_values.pop(0)\n",
    "    after_values.pop(-1)\n",
    "    # We calculate the total return by calculating the return\n",
    "    # between each transaction, and solving for the cumulative\n",
    "    # return.\n",
    "    growth = np.array(before_values) / np.array(after_values)\n",
    "    portfolio_return = np.prod(growth[~np.isnan(growth)])\n",
    "    years = (end_date - begin_date).days / 365\n",
    "    if years == 0 or portfolio_return == 0:\n",
    "        cagr = 0\n",
    "    else:\n",
    "        cagr = portfolio_return**(1 / years)\n",
    "    # Cumulative return calculation\n",
    "    tx_dates.pop(0)\n",
    "    tx_dates = np.array(tx_dates)\n",
    "    tx_dates = tx_dates[~np.isnan(growth)]\n",
    "    cum_growth = np.cumprod(growth[~np.isnan(growth)])\n",
    "    growth_df = pd.DataFrame([\n",
    "        {\n",
    "            'date': tx_dates[i],\n",
    "            'cum_growth': cum_growth[i]\n",
    "        } for i in range(len(cum_growth))\n",
    "    ])\n",
    "    return {\n",
    "        'begin_date': begin_date,\n",
    "        'end_date': end_date,\n",
    "        'portfolio_return': portfolio_return,\n",
    "        'annual_cagr': cagr,\n",
    "        'growth': growth_df\n",
    "    }\n",
    "\n",
    "def return_for_senator(rows, date_col='tx_date'):\n",
    "    stocks = defaultdict(int)\n",
    "    # Value of portfolio at various timepoints to calculate return\n",
    "    portfolio_value_before_tx = []\n",
    "    portfolio_value_after_tx = []\n",
    "    tx_dates = []\n",
    "    rows = rows.sort_values(by=date_col)\n",
    "    for _, row in rows.iterrows():\n",
    "        date = row[date_col]\n",
    "        if date_col == 'file_date':\n",
    "            # We can't execute the trade the same day\n",
    "            date += dt.timedelta(days=1)\n",
    "        try:\n",
    "            value_before_tx = portfolio_value(stocks, date)\n",
    "            if 'Purchase' in row['order_type']:\n",
    "                tx_amt = row['tx_estimate']\n",
    "                n_units = tx_amt / ticker_at_date(row['ticker'], date)\n",
    "                stocks[row['ticker']] += n_units\n",
    "            elif 'Sale' in row['order_type']:\n",
    "                stock_price = ticker_at_date(row['ticker'], date)\n",
    "                current_value = stock_price * stocks[row['ticker']]\n",
    "                if 'Full' in row['order_type'] or\\\n",
    "                    same_bucket(row['tx_estimate'], current_value):\n",
    "                    stocks[row['ticker']] = 0\n",
    "                else:\n",
    "                    new_n_units = stocks[row['ticker']] - \\\n",
    "                        row['tx_estimate'] / stock_price\n",
    "                    stocks[row['ticker']] = max(0, new_n_units)\n",
    "            portfolio_value_before_tx.append(value_before_tx)\n",
    "            portfolio_value_after_tx.append(portfolio_value(stocks, date))\n",
    "            tx_dates.append(date)\n",
    "        except Exception as e:\n",
    "            print('Ticker {0} gave exception: {1}'\n",
    "                  .format(row['ticker'], e))\n",
    "    return calculate_return(\n",
    "        portfolio_value_before_tx,\n",
    "        portfolio_value_after_tx,\n",
    "        begin_date=min(rows[date_col]),\n",
    "        end_date=max(rows[date_col]),\n",
    "        tx_dates=tx_dates\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "senator_returns = []\n",
    "senator_tx_growth = {}\n",
    "senator_file_growth = {}\n",
    "senator_names = set(clean_senators['full_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "failed_senators = {}\n",
    "print('{} senators total'.format(len(senator_names)))\n",
    "for n in senator_names:\n",
    "    print('Starting {}'.format(n))\n",
    "    if n in senator_tx_growth:\n",
    "        # Don't re-calculate for a given senator.\n",
    "        continue\n",
    "    try:\n",
    "        tx_return = return_for_senator(\n",
    "            clean_senators[clean_senators['full_name'] == n],\n",
    "            date_col='tx_date')\n",
    "        file_return = return_for_senator(\n",
    "            clean_senators[clean_senators['full_name'] == n],\n",
    "            date_col='file_date')\n",
    "        senator_returns.append({\n",
    "            'full_name': n,\n",
    "            'tx_total_return': tx_return['portfolio_return'],\n",
    "            'tx_cagr': tx_return['annual_cagr'],\n",
    "            'file_total_return': file_return['portfolio_return'],\n",
    "            'file_cagr': file_return['annual_cagr']\n",
    "        })\n",
    "        senator_tx_growth[n] = tx_return['growth']\n",
    "        senator_file_growth[n] = file_return['growth']\n",
    "    except Exception as e:\n",
    "        print('Failed {0} with exception {1}'.format(n, e))\n",
    "        failed_senators[n] = e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the results to see the senators that outperformed the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_senator_growth(growth):\n",
    "    \"\"\" Plot the senator's portfolio growth against the S&P 500. \"\"\"\n",
    "    df = pd.DataFrame(growth)\n",
    "    plt.plot_date(df['date'], df['cum_growth'], '-')\n",
    "    spy = load_for_ticker('SPY')\n",
    "    spy = spy[(spy['date'] >= min(df['date']))\n",
    "              & (spy['date'] <= max(df['date']))]\n",
    "    spy_prices = spy['price']\n",
    "    dates = spy['date']\n",
    "    dates = dates.iloc[1:]\n",
    "    spy_diff = np.cumprod(np.diff(spy_prices) / spy_prices[1:] + 1)\n",
    "    plt.plot_date(dates, spy_diff, '-')\n",
    "    plt.show()\n",
    "    senator_growth = np.array(df['cum_growth'])\n",
    "    print('Earliest date: {}'.format(min(df['date'])))\n",
    "    print('Market return: {}'.format(\n",
    "        spy_prices.iloc[-1] / spy_prices.iloc[0]))\n",
    "    print('Senator return: {}'.format(\n",
    "        senator_growth[-1] / senator_growth[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(senator_returns)\n",
    "df = df[(df['tx_total_return'] > df['tx_cagr']) & df['tx_cagr'] > 0]\n",
    "df.sort_values('tx_cagr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_senator_growth(senator_tx_growth['Angus S King, Jr.'])\n",
    "clean_senators[clean_senators['full_name'] == 'Angus S King, Jr.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "Author: Neel Somani, Software Engineer\n",
    "\n",
    "Email: neel@berkeley.edu\n",
    "\n",
    "Website: https://www.ocf.berkeley.edu/~neel/\n",
    "\n",
    "Updated On: 2020-05-06"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
